{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://www.xicidaili.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml import etree\n",
    "from requests.exceptions import ReadTimeout,ConnectionError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanString(oldString):\n",
    "    newString = oldString.replace('\\n', '')\n",
    "    newString = newString.replace('\\\\', '')\n",
    "    newString = newString.replace('  ', '')\n",
    "    newString = newString.replace('   ', '')\n",
    "    return newString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveTotxt(disNum, date_times, user1s, user2s, content_goods, title):\n",
    "    with open('data/' + title + '.txt', 'a+', encoding='utf-8') as f:\n",
    "        for i in range(date_times.__len__()):\n",
    "            f.write(str(disNum) + ',')\n",
    "            f.write(date_times[i] + ',')\n",
    "            f.write(user1s[i] + ',')\n",
    "            f.write(user2s[i] + ',')\n",
    "            f.write(content_goods[i].replace(',','，') + '\\n')\n",
    "            disNum += 1\n",
    "        f.close()\n",
    "    return disNum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_json(myjson):\n",
    "    try:\n",
    "        json.loads(myjson)\n",
    "    except ValueError:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDiscussionFromOnePage(url, headers, proxies, disNum, title):\n",
    "    readTimeout = False\n",
    "    readTimeout_count = 0\n",
    "    while True:\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers, timeout = 20)\n",
    "            break\n",
    "        except ReadTimeout:\n",
    "            print('Get a timeout')\n",
    "            readTimeout_count += 1\n",
    "        except ConnectionError:\n",
    "            print('Get a timeout')\n",
    "            readTimeout_count += 1\n",
    "        if readTimeout_count == 5:\n",
    "            readTimeout = True\n",
    "            break\n",
    "            \n",
    "    if readTimeout == True:\n",
    "        print('Always timeout. Shiped current page')\n",
    "    else:\n",
    "        if response.status_code == 200 and is_json(response.text):\n",
    "            jsonData = response.json()\n",
    "            htmlStr = str(jsonData['data']['html'])\n",
    "            htmlStr = cleanString(htmlStr)\n",
    "            html = etree.HTML(htmlStr)\n",
    "            html_data = html.xpath('//div[@class=\"list_box\"]/div[@class=\"list_ul\"]/div[@class=\"list_li S_line1 clearfix\"]')\n",
    "            date_times = []\n",
    "            user1s = []\n",
    "            user2s = []\n",
    "            content_goods = []\n",
    "            for d in html_data:\n",
    "                date_time = d.xpath('./child::div[@class=\"list_con\"]/div[@class=\"WB_func clearfix\"]/div[@class=\"WB_from S_txt2\"]//text()')[0]\n",
    "                aNum = d.xpath('./child::div[@class=\"list_con\"]/div[@class=\"WB_text\"]/a').__len__()\n",
    "                content_bad = d.xpath('./child::div[@class=\"list_con\"]/div[@class=\"WB_text\"]//text()')\n",
    "                user1 = content_bad[0]\n",
    "                content_good = ''\n",
    "                if content_bad.__len__()<4 or aNum<2:\n",
    "                    for i in range(content_bad.__len__()-1):\n",
    "                        content_good += content_bad[i+1]\n",
    "                    user2 = ''\n",
    "                else:\n",
    "                    for i in range(content_bad.__len__()-3):\n",
    "                        content_good += content_bad[i+3]\n",
    "                    user2 = content_bad[2].replace('@','')\n",
    "                content_good = content_good.replace('：','')\n",
    "                content_good = content_good.replace(':','')\n",
    "                date_times.append(date_time)\n",
    "                user1s.append(user1)\n",
    "                user2s.append(user2)\n",
    "                content_goods.append(content_good)\n",
    "            return saveTotxt(disNum, date_times, user1s, user2s, content_goods, title)\n",
    "        elif response.status_code == 414:\n",
    "            print('Get a 414 on ContentGet')\n",
    "            time.sleep(30)\n",
    "            return getDiscussionFromOnePage(url, headers, proxies, disNum, title)\n",
    "        elif response.status_code == 503:\n",
    "            print('Get a 503 on ContentGet')\n",
    "            time.sleep(3)\n",
    "            return getDiscussionFromOnePage(url, headers, proxies, disNum, title)\n",
    "        elif (response.status_code == 200 and is_json(response.text) == False) or response.status_code == 404:\n",
    "            print('Cookies out time')\n",
    "            exit()\n",
    "        else:\n",
    "            print(str(response.status_code))\n",
    "            print('Unknow ERROR')\n",
    "            exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAUrlByPage(old_url, pageNum):\n",
    "    url_split = old_url.split('&')\n",
    "    new_url = ''\n",
    "    for i in range(url_split.__len__()):\n",
    "        if url_split[i].find('page=') == -1 and i < url_split.__len__()-1:\n",
    "            new_url += url_split[i] + '&'\n",
    "        elif url_split[i].find('page=') == -1 and i == url_split.__len__()-1:\n",
    "            new_url += url_split[i]\n",
    "        else:\n",
    "            new_url += 'page=' + str(pageNum) + '&'\n",
    "    return new_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWeiboDiscussion(url, disNum, title, currPage):\n",
    "    proxies = {\n",
    "        \"https\":\"https://61.128.208.94:3128\",\n",
    "        \"https\":\"https://183.129.207.73:14823\",\n",
    "        \"https\":\"https://223.223.187.195:80\",\n",
    "        \"https\":\"https://203.93.209.163:53281\",\n",
    "        \"https\":\"https://59.37.18.243:3128\"\n",
    "    }\n",
    "    headers = {\n",
    "        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',\n",
    "        'Accept-Encoding': 'gzip, deflate, br',\n",
    "        'Accept-Language': 'zh-CN,zh;q=0.9',\n",
    "        'Cache-Control': 'max-age=0',\n",
    "        'Connection': 'close',\n",
    "        'Cookie': 'SINAGLOBAL=4454129403737.665.1540017698992; wvr=6; wb_view_log_5485650173=1440*9001; YF-Ugrow-G0=169004153682ef91866609488943c77f; SCF=AkAGBzmnRrBsZyLGJUwLkv_HUqu2cIVaKpTGSpJa2wjbmiEvsvr-ESPlL0a6ctHSmsImUu8ZYTdZlX2_ozo9pfU.; SUB=_2A252z47oDeRhGeNK41cX9S7NzD-IHXVVvOcgrDV8PUJbmtBeLRTQkW9NSVAC9kn3nCaaE6CG1ua__mrG69wVuDK7; SUBP=0033WrSXqPxfM725Ws9jqgMF55529P9D9WhkzAEoOqAfFKxUuP63.RO75JpX5K-hUgL.Fo-X1h-cSK5pS0e2dJLoIfQLxK-L1K5L1heLxK-L1hML1h5LxKML1-zL1KnLxKBLBonLB-BLxKMLBozLB--LxKqL1KqLBo.LxKBLBonLB.2LxKML12zL1KMLxKBLBonLB-BLxKML12-L12zt; SUHB=0Jvg4GJCEcSlcz; ALF=1571631670; SSOLoginState=1540095673; YF-V5-G0=5468b83cd1a503b6427769425908497c; _s_tentry=login.sina.com.cn; UOR=,,login.sina.com.cn; Apache=3309785789590.145.1540095677557; ULV=1540095677594:2:2:1:3309785789590.145.1540095677557:1540017699000; YF-Page-G0=5c7144e56a57a456abed1d1511ad79e8',\n",
    "        'Host': 'weibo.com',\n",
    "        'Upgrade-Insecure-Requests': '1',\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.3497.92 Safari/537.36'\n",
    "    }\n",
    "    pageNumFlag = False\n",
    "    try:\n",
    "        requests.adapters.DEFAULT_RETRIES = 5\n",
    "        response = requests.get(url, headers=headers, timeout = 20)\n",
    "        pageNumFlag = True\n",
    "    except ReadTimeout:\n",
    "        print('Failed. Get page num failed1')\n",
    "    except ConnectionError:\n",
    "        print('Failed. Get page num failed2')\n",
    "    if pageNumFlag == True and response.status_code == 200 and is_json(response.text):\n",
    "        jsonData = response.json()\n",
    "        pageNum = int(jsonData['data']['page']['totalpage'])\n",
    "        print(pageNum)\n",
    "        for i in range(pageNum-currPage):\n",
    "            url = getAUrlByPage(url, i+currPage+1)\n",
    "            disNum = getDiscussionFromOnePage(url, headers, proxies, disNum, title)\n",
    "            print(str(i+currPage+1) + ' page finished (Total: ' + str(pageNum) + ')')\n",
    "#         countNum = int(jsonData['data']['count'])\n",
    "#         countNum += disNum - 1\n",
    "#         i = 0\n",
    "#         while(disNum < countNum):\n",
    "#             url = getAUrlByPage(url, i+currPage+1)\n",
    "#             disNum = getDiscussionFromOnePage(url, headers, proxies, disNum, title)\n",
    "#             print(str(disNum) + ' discussion finished (Total: ' + str(countNum) + ')')\n",
    "#             i += 1\n",
    "        print('Finished')\n",
    "    elif pageNumFlag == True and response.status_code == 414:\n",
    "        print('Get a 414 on pageNumGet')\n",
    "        time.sleep(30)\n",
    "        return getWeiboDiscussion(url, disNum, title, currPage)\n",
    "    elif pageNumFlag == True and response.status_code == 503:\n",
    "        print('Get a 503 on pageNumGet')\n",
    "        time.sleep(3)\n",
    "        return getWeiboDiscussion(url, disNum, title, currPage)\n",
    "    elif (response.status_code == 200 and is_json(response.text) == False) or response.status_code == 404:\n",
    "        print('Cookies out time')\n",
    "        exit()\n",
    "    else:\n",
    "        print(str(response.status_code))\n",
    "        print('Unknow ERROR')\n",
    "        exit()\n",
    "    return disNum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "948\n",
      "707 page finished (Total: 948)\n",
      "708 page finished (Total: 948)\n",
      "709 page finished (Total: 948)\n",
      "710 page finished (Total: 948)\n",
      "711 page finished (Total: 948)\n",
      "712 page finished (Total: 948)\n",
      "713 page finished (Total: 948)\n",
      "714 page finished (Total: 948)\n",
      "715 page finished (Total: 948)\n",
      "716 page finished (Total: 948)\n",
      "717 page finished (Total: 948)\n",
      "718 page finished (Total: 948)\n",
      "719 page finished (Total: 948)\n",
      "720 page finished (Total: 948)\n",
      "721 page finished (Total: 948)\n",
      "722 page finished (Total: 948)\n",
      "723 page finished (Total: 948)\n",
      "724 page finished (Total: 948)\n",
      "725 page finished (Total: 948)\n",
      "726 page finished (Total: 948)\n",
      "727 page finished (Total: 948)\n",
      "728 page finished (Total: 948)\n",
      "729 page finished (Total: 948)\n",
      "730 page finished (Total: 948)\n",
      "731 page finished (Total: 948)\n",
      "732 page finished (Total: 948)\n",
      "733 page finished (Total: 948)\n",
      "734 page finished (Total: 948)\n",
      "735 page finished (Total: 948)\n",
      "736 page finished (Total: 948)\n",
      "737 page finished (Total: 948)\n",
      "738 page finished (Total: 948)\n",
      "739 page finished (Total: 948)\n",
      "740 page finished (Total: 948)\n",
      "741 page finished (Total: 948)\n",
      "742 page finished (Total: 948)\n",
      "743 page finished (Total: 948)\n",
      "744 page finished (Total: 948)\n",
      "745 page finished (Total: 948)\n",
      "746 page finished (Total: 948)\n",
      "747 page finished (Total: 948)\n",
      "748 page finished (Total: 948)\n",
      "749 page finished (Total: 948)\n",
      "750 page finished (Total: 948)\n",
      "751 page finished (Total: 948)\n",
      "752 page finished (Total: 948)\n",
      "753 page finished (Total: 948)\n",
      "754 page finished (Total: 948)\n",
      "755 page finished (Total: 948)\n",
      "756 page finished (Total: 948)\n",
      "757 page finished (Total: 948)\n",
      "758 page finished (Total: 948)\n",
      "759 page finished (Total: 948)\n",
      "760 page finished (Total: 948)\n",
      "761 page finished (Total: 948)\n",
      "762 page finished (Total: 948)\n",
      "763 page finished (Total: 948)\n",
      "764 page finished (Total: 948)\n",
      "765 page finished (Total: 948)\n",
      "766 page finished (Total: 948)\n",
      "767 page finished (Total: 948)\n",
      "768 page finished (Total: 948)\n",
      "769 page finished (Total: 948)\n",
      "770 page finished (Total: 948)\n",
      "771 page finished (Total: 948)\n",
      "772 page finished (Total: 948)\n",
      "773 page finished (Total: 948)\n",
      "774 page finished (Total: 948)\n",
      "775 page finished (Total: 948)\n",
      "776 page finished (Total: 948)\n",
      "777 page finished (Total: 948)\n",
      "778 page finished (Total: 948)\n",
      "779 page finished (Total: 948)\n",
      "780 page finished (Total: 948)\n",
      "781 page finished (Total: 948)\n",
      "782 page finished (Total: 948)\n",
      "783 page finished (Total: 948)\n",
      "784 page finished (Total: 948)\n",
      "785 page finished (Total: 948)\n",
      "786 page finished (Total: 948)\n",
      "787 page finished (Total: 948)\n",
      "788 page finished (Total: 948)\n",
      "789 page finished (Total: 948)\n",
      "790 page finished (Total: 948)\n",
      "791 page finished (Total: 948)\n",
      "792 page finished (Total: 948)\n",
      "793 page finished (Total: 948)\n",
      "794 page finished (Total: 948)\n",
      "795 page finished (Total: 948)\n",
      "796 page finished (Total: 948)\n",
      "797 page finished (Total: 948)\n",
      "798 page finished (Total: 948)\n",
      "799 page finished (Total: 948)\n",
      "800 page finished (Total: 948)\n",
      "801 page finished (Total: 948)\n",
      "802 page finished (Total: 948)\n",
      "803 page finished (Total: 948)\n",
      "804 page finished (Total: 948)\n",
      "805 page finished (Total: 948)\n",
      "806 page finished (Total: 948)\n",
      "807 page finished (Total: 948)\n",
      "808 page finished (Total: 948)\n",
      "809 page finished (Total: 948)\n",
      "810 page finished (Total: 948)\n",
      "811 page finished (Total: 948)\n",
      "812 page finished (Total: 948)\n",
      "813 page finished (Total: 948)\n",
      "814 page finished (Total: 948)\n",
      "815 page finished (Total: 948)\n",
      "816 page finished (Total: 948)\n",
      "817 page finished (Total: 948)\n",
      "818 page finished (Total: 948)\n"
     ]
    }
   ],
   "source": [
    "title = '范冰冰偷税漏税'\n",
    "disNum = 12021\n",
    "currPage = 706\n",
    "url = 'https://weibo.com/aj/v6/comment/big?ajwvr=6&id=4291181112267037&root_comment_max_id=603649047522147&root_comment_max_id_type=&root_comment_ext_param=&page=1&filter=all'\n",
    "disNum = getWeiboDiscussion(url, disNum, title, currPage)\n",
    "url = 'https://weibo.com/aj/v6/comment/big?ajwvr=6&id=4291110169902050&root_comment_max_id=154620403457&root_comment_max_id_type=&root_comment_ext_param=&page=1&filter=all'\n",
    "disNum = getWeiboDiscussion(url, disNum, title, 0)\n",
    "url = 'https://weibo.com/aj/v6/comment/big?ajwvr=6&id=4291017299808168&root_comment_max_id=154608376240&root_comment_max_id_type=&root_comment_ext_param=&page=1&filter=all'\n",
    "disNum = getWeiboDiscussion(url, disNum, title, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
